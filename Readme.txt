"Welcome to the Redbus Data Scraping Project with Selenium and Dynamic Filtering using Streamlit.

1. First, ensure that you have installed all the required packages to run the code. 

2. Run the `Redbus_scrapper.py` file. This script will automatically navigate to the Redbus website and scrape details of both government and private buses. The scraped data will be stored in your SQL database, and a `.csv` file containing all the route links will be created.

3. Using these route links, Selenium will scrape additional data from the website. A total of 15,466 records have been collected. 

4. The Streamlit app has been created based on this data. Note that the Streamlit app does not connect directly to the SQL database. Instead, it retrieves data from the `.csv` file where the SQL data is stored.

Enjoy exploring the data and the Streamlit app!"
